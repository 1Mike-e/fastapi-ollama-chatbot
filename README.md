# ğŸ¤– FastAPI Ollama Chatbot

A simple FastAPI application that connects to a local [Ollama](https://ollama.com/) AI model (`mistral`, `llama3`, etc.) to provide a chatbot interface via an HTTP API and static frontend.

---

## ğŸ“¦ Features

- ğŸ”Œ REST API endpoint for chat interaction
- ğŸ§  Works with local Ollama models like `mistral` or `llama3`
- ğŸŒ Serves a static HTML frontend from `/static`
- âš ï¸ Proper error handling and JSON validation
- ğŸš€ Easy to run and deploy

---

## ğŸ› ï¸ Project Structure

â”œâ”€â”€ app.py # FastAPI application
â”œâ”€â”€ static/
â”‚ â””â”€â”€ index.html # Frontend HTML served at root "/"
â””â”€â”€ README.md


## âš™ï¸ Requirements

- Python 3.8+
- [Ollama](https://ollama.com/) installed and running locally
- Dependencies from `fastapi`, `uvicorn`, and `requests`

Install with:

```bash
pip install fastapi uvicorn requests
